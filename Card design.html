<!-- CARD -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
 <h1>.CARD. </h1>
 <STYLE>
    body{
        background-color: grey;
    }
.card{
    background-color: white;
    width:300px;
    height:450px;
    border-radius:8px;
}
.image{
    margin:1px;
    padding:10px;
}
.image img{
    border-radius: 8px;
}
.content{
    border:1px solid;
    margin:15px;
    padding: 4px;
    width:260px;
    height:170px;
    overflow:hidden scroll;
    border-radius: 5px;
    cursor:help;
}
.button span{
    border:1px solid ;
    border-radius: 15px;
    margin:15px;
    padding: 3px;
    font-size:15px;
    font-weight:450;
    text-align: center;
}
.right{
    
    margin: 15px;
    padding: 3px;
    border-radius: 15px;
    color:rgb(93, 93, 212);
    background-color: rgb(219, 221, 238);
    font-weight: bold;
    text-align: center;
}
.button span:hover{
    background-color: rgb(219, 221, 238);
    color:black;
}
 </STYLE>
 </head>
 <body>
    <div class="card">
        <div class="image">
            <img  width=280px src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_SS.width-1300.jpg " alt="">
        </div>
        <div class="button">
            <span > About </span>
            <span > Use it now</span>
        </div>
        <div class="box">
            <div class="content">
                Google Gemini, previously known as Google Bard, is an AI-powered chatbot. It uses machine learning and natural language processing (NLP) to provide humanlike responses to text, image, and audio prompts. Gemini performs several functions.It allows advertisers to purchase native ad space across the Google Display Network.In theory, this should mean Google Gemini understands things in a more intuitive manner. Take a phrase like "monkey business": if an AI is just trained on images tagged "monkey" and "business," it's likely to just think of monkeys in suits when asked to draw something related to it. On the other hand, if the AI for understanding images and the AI for understanding language are trained at the same time, the entire model should have a deeper understanding of the mischievous and deceitful connotations of the phrase. It's ok for the monkeys to be wearing suitsâ€”but they'd better be throwing poo. 
                By training all its modalities at once, Google claims that Gemini can "seamlessly understand and reason about all kinds of inputs from the ground up." For example, it can understand charts and the captions that accompany them, read text from signs, and otherwise integrate information from multiple modalities. While this was relatively unique last year when Gemini first launched, both Claude 3.5 and GPT-4o have a lot of the same multimodal features.
            </div>
            <div class="right">
                &copy Rights reserved to Pranav Swami.
            </div>
        </div>
    </div> 
</body>
</html>
